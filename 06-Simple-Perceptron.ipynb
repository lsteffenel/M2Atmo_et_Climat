{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# <!-- TITLE --> [PER57] - Perceptron Model 1957\n<!-- DESC --> Dans cet exemple nous allons utiliser la bibliothèque sklearn pour implémenter un Perceptron (modèle 1957) et travailler sur les données du dataset IRIS (qui datent de 1936) !\n<!-- AUTHOR : Jean-Luc Parouty (CNRS/SIMaP) -->\n\n## Objectifs :\n - Implémenter un classifieur linéaire historique avec un dataset historique !\n - L'objectif est de prédire la variété d'Iris à partir de la taille de ses pétales/sépales.\n - Identifier les limitations d'un seul neurone  \n\nLe [dataset IRIS](https://archive.ics.uci.edu/ml/datasets/Iris) est probablement l'un des plus anciens datasets, datant de 1936.\n\n## Ce qu'on fera :\n - Récupérérer le dataset via la bibliothèque scikit-learn\n - l'entraîner et faire une classification\n\n## Etape 1 - Importation des bibliothèques et initialisation","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.datasets     import load_iris\nfrom sklearn.linear_model import Perceptron\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib\n\nimport os,sys\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Etape 2 - Préparer le dataset IRIS\n\nLa plupart des bibliothèques de machine learning ont des datasets \"exemple\" directement accessibles\nDans le cas de Scikit-Learn, ces datasets se trouvent dans le module suivant :\nComment récupérer un dataset : http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets  \nLa liste des datesets : http://scikit-learn.org/stable/datasets/index.html  \n\nLes différents attributs (X) :\n- 0 : sepal length in cm\n- 1 : sepal width in cm\n- 2 : petal length in cm\n- 3 : petal width in cm  \n\nLes classes (y) :\n- 0 : class 0=Iris-Setosa, 1=Iris-Versicolour, 2=Iris-Virginica\n\n### 2.1 - Charger le dataset","metadata":{}},{"cell_type":"code","source":"x0,y0 = load_iris(return_X_y=True)\n\nx = x0[:, (2,3)]     # nous allons garder juste les features 2 et 3 (données des pétales)\ny = y0.copy()\n\ny[ y0==0 ] = 1       # 1 = Iris setosa\ny[ y0>=1 ] = 0       # 0 = not iris setosa\n\ndf=pd.DataFrame.from_dict({'Length (x1)':x[:,0], 'Width (x2)':x[:,1], 'Setosa {0,1} (y)':y})\ndisplay(df)\n\nprint(f'x shape : {x.shape}')\nprint(f'y shape : {y.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 - Créer les datasets d'entraînement (Train) et de Test","metadata":{}},{"cell_type":"code","source":"def shuffle_np_dataset(x, y): # fonction pour mélanger aléatoirement le dataset\n    \"\"\"\n    Shuffle a dataset (x,y)\n    args:\n        x,y : dataset\n    return:\n        x,y mixed\n    \"\"\"\n    assert (len(x) == len(y)), \"x and y must have same size\"\n    p = np.random.permutation(len(x))\n    return x[p], y[p]\n\nx,y = shuffle_np_dataset(x, y)\n    \nn=int(len(x)*0.8)\nx_train = x[:n]\ny_train = y[:n]\nx_test  = x[n:]\ny_test  = y[n:]\n\nprint(f'x_train shape : {x_train.shape}')\nprint(f'y_train shape : {y_train.shape}')\nprint(f'x_test shape  : {x_test.shape}')\nprint(f'y_test shape  : {y_test.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3 - Créer un perceptron et l'entraîner","metadata":{}},{"cell_type":"code","source":"pct = Perceptron(max_iter=100, random_state=82, tol=0.01, verbose=1)\n# nous avons limité l'entraînement à un max de 100 itérations\n# l'option \"tol\" permet d'arrêter l'entraînement plus tôt, si le gain est inférieur à 0.01\n\npct.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Etape 4 - Prédictions\n\nLe perceptron a été entraîné uniquement sur les données Train. On peut maintenant faire des estimations avec les données Test.\nLes colonnes `y_test`et `y_pred` correspondent respectivement aux labels du dataset et aux labels prédicts.","metadata":{}},{"cell_type":"code","source":"y_pred = pct.predict(x_test) \n\ndf=pd.DataFrame.from_dict({'Length (x1)':x_test[:,0], 'Width (x2)':x_test[:,1], 'y_test':y_test, 'y_pred':y_pred})\ndisplay(df[:15])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5 - Visualisation\n\nLe paragraphe suivant fait la visualisation des données précédentes. Il affiche les données Train (en couleurs foncées) et les données Test. Les couleurs correspondent aux labels, et la ligne pointillée montre la séparation faite par le perceptron.","metadata":{}},{"cell_type":"code","source":"def plot_perceptron(x_train,y_train,x_test,y_test):\n    a = -pct.coef_[0][0] / pct.coef_[0][1]\n    b = -pct.intercept_ / pct.coef_[0][1]\n    box=[x.min(axis=0)[0],x.max(axis=0)[0],x.min(axis=0)[1],x.max(axis=0)[1]]\n    mx=(box[1]-box[0])/20\n    my=(box[3]-box[2])/20\n    box=[box[0]-mx,box[1]+mx,box[2]-my,box[3]+my]\n\n    fig, axs = plt.subplots(1, 1)\n    fig.set_size_inches(10,6)\n \n    axs.plot(x_train[y_train==1, 0], x_train[y_train==1, 1], \"o\", color='tomato', label=\"Iris-Setosa\")\n    axs.plot(x_train[y_train==0, 0], x_train[y_train==0, 1], \"o\", color='steelblue',label=\"Autres\")\n    \n    axs.plot(x_test[y_pred==1, 0],   x_test[y_pred==1, 1],   \"o\", color='lightsalmon', label=\"Iris-Setosa (pred)\")\n    axs.plot(x_test[y_pred==0, 0],   x_test[y_pred==0, 1],   \"o\", color='lightblue',   label=\"Autres (pred)\")\n    \n    axs.plot([box[0], box[1]], [a*box[0]+b, a*box[1]+b], \"k--\", linewidth=2)\n    axs.set_xlabel(\"Petal length (cm)\", labelpad=15) #, fontsize=14)\n    axs.set_ylabel(\"Petal width (cm)\",  labelpad=15) #, fontsize=14)\n    axs.legend(loc=\"lower right\", fontsize=14)\n    axs.set_xlim(box[0],box[1])\n    axs.set_ylim(box[2],box[3])\n    plt.show()\n    \nplot_perceptron(x_train,y_train, x_test,y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}